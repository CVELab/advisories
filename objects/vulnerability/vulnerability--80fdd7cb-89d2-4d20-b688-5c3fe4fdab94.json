{
    "type": "bundle",
    "id": "bundle--d655fb6b-82e5-423b-b45d-acd2c0cdabe1",
    "objects": [
        {
            "type": "vulnerability",
            "spec_version": "2.1",
            "id": "vulnerability--80fdd7cb-89d2-4d20-b688-5c3fe4fdab94",
            "created_by_ref": "identity--8ce3f695-d5a4-4dc8-9e93-a65af453a31a",
            "created": "2024-05-21T15:17:46.220261Z",
            "modified": "2024-05-21T15:17:46.220261Z",
            "name": "CVE-2021-47227",
            "description": "In the Linux kernel, the following vulnerability has been resolved:\n\nx86/fpu: Prevent state corruption in __fpu__restore_sig()\n\nThe non-compacted slowpath uses __copy_from_user() and copies the entire\nuser buffer into the kernel buffer, verbatim.  This means that the kernel\nbuffer may now contain entirely invalid state on which XRSTOR will #GP.\nvalidate_user_xstate_header() can detect some of that corruption, but that\nleaves the onus on callers to clear the buffer.\n\nPrior to XSAVES support, it was possible just to reinitialize the buffer,\ncompletely, but with supervisor states that is not longer possible as the\nbuffer clearing code split got it backwards. Fixing that is possible but\nnot corrupting the state in the first place is more robust.\n\nAvoid corruption of the kernel XSAVE buffer by using copy_user_to_xstate()\nwhich validates the XSAVE header contents before copying the actual states\nto the kernel. copy_user_to_xstate() was previously only called for\ncompacted-format kernel buffers, but it works for both compacted and\nnon-compacted forms.\n\nUsing it for the non-compacted form is slower because of multiple\n__copy_from_user() operations, but that cost is less important than robust\ncode in an already slow path.\n\n[ Changelog polished by Dave Hansen ]",
            "external_references": [
                {
                    "source_name": "cve",
                    "external_id": "CVE-2021-47227"
                }
            ]
        }
    ]
}