{
    "type": "bundle",
    "id": "bundle--ed873f9d-71f4-494d-88e9-5a813cf3833c",
    "objects": [
        {
            "type": "vulnerability",
            "spec_version": "2.1",
            "id": "vulnerability--b8bffbf2-6f8f-42d7-9fc6-0020c438ca51",
            "created_by_ref": "identity--8ce3f695-d5a4-4dc8-9e93-a65af453a31a",
            "created": "2024-02-28T09:15:23.704703Z",
            "modified": "2024-02-28T09:15:23.704703Z",
            "name": "CVE-2021-47011",
            "description": "In the Linux kernel, the following vulnerability has been resolved:\n\nmm: memcontrol: slab: fix obtain a reference to a freeing memcg\n\nPatch series \"Use obj_cgroup APIs to charge kmem pages\", v5.\n\nSince Roman's series \"The new cgroup slab memory controller\" applied.\nAll slab objects are charged with the new APIs of obj_cgroup.  The new\nAPIs introduce a struct obj_cgroup to charge slab objects.  It prevents\nlong-living objects from pinning the original memory cgroup in the\nmemory.  But there are still some corner objects (e.g.  allocations\nlarger than order-1 page on SLUB) which are not charged with the new\nAPIs.  Those objects (include the pages which are allocated from buddy\nallocator directly) are charged as kmem pages which still hold a\nreference to the memory cgroup.\n\nE.g.  We know that the kernel stack is charged as kmem pages because the\nsize of the kernel stack can be greater than 2 pages (e.g.  16KB on\nx86_64 or arm64).  If we create a thread (suppose the thread stack is\ncharged to memory cgroup A) and then move it from memory cgroup A to\nmemory cgroup B.  Because the kernel stack of the thread hold a\nreference to the memory cgroup A.  The thread can pin the memory cgroup\nA in the memory even if we remove the cgroup A.  If we want to see this\nscenario by using the following script.  We can see that the system has\nadded 500 dying cgroups (This is not a real world issue, just a script\nto show that the large kmallocs are charged as kmem pages which can pin\nthe memory cgroup in the memory).\n\n\t#!/bin/bash\n\n\tcat /proc/cgroups | grep memory\n\n\tcd /sys/fs/cgroup/memory\n\techo 1 > memory.move_charge_at_immigrate\n\n\tfor i in range{1..500}\n\tdo\n\t\tmkdir kmem_test\n\t\techo $$ > kmem_test/cgroup.procs\n\t\tsleep 3600 &\n\t\techo $$ > cgroup.procs\n\t\techo `cat kmem_test/cgroup.procs` > cgroup.procs\n\t\trmdir kmem_test\n\tdone\n\n\tcat /proc/cgroups | grep memory\n\nThis patchset aims to make those kmem pages to drop the reference to\nmemory cgroup by using the APIs of obj_cgroup.  Finally, we can see that\nthe number of the dying cgroups will not increase if we run the above test\nscript.\n\nThis patch (of 7):\n\nThe rcu_read_lock/unlock only can guarantee that the memcg will not be\nfreed, but it cannot guarantee the success of css_get (which is in the\nrefill_stock when cached memcg changed) to memcg.\n\n  rcu_read_lock()\n  memcg = obj_cgroup_memcg(old)\n  __memcg_kmem_uncharge(memcg)\n      refill_stock(memcg)\n          if (stock->cached != memcg)\n              // css_get can change the ref counter from 0 back to 1.\n              css_get(&memcg->css)\n  rcu_read_unlock()\n\nThis fix is very like the commit:\n\n  eefbfa7fd678 (\"mm: memcg/slab: fix use after free in obj_cgroup_charge\")\n\nFix this by holding a reference to the memcg which is passed to the\n__memcg_kmem_uncharge() before calling __memcg_kmem_uncharge().",
            "external_references": [
                {
                    "source_name": "cve",
                    "external_id": "CVE-2021-47011"
                }
            ]
        }
    ]
}