{
    "type": "bundle",
    "id": "bundle--f7854a8d-8be1-4d5f-aef9-7e1ab57bf9db",
    "objects": [
        {
            "type": "vulnerability",
            "spec_version": "2.1",
            "id": "vulnerability--4f28b0a8-7cb5-449f-8ee6-64190035d791",
            "created_by_ref": "identity--8ce3f695-d5a4-4dc8-9e93-a65af453a31a",
            "created": "2021-12-24T00:25:13.562379Z",
            "modified": "2021-12-24T00:25:13.562379Z",
            "name": "CVE-2021-43854",
            "description": "NLTK (Natural Language Toolkit) is a suite of open source Python modules, data sets, and tutorials supporting research and development in Natural Language Processing. Versions prior to 3.6.5 are vulnerable to regular expression denial of service (ReDoS) attacks. The vulnerability is present in PunktSentenceTokenizer, sent_tokenize and word_tokenize. Any users of this class, or these two functions, are vulnerable to the ReDoS attack. In short, a specifically crafted long input to any of these vulnerable functions will cause them to take a significant amount of execution time. If your program relies on any of the vulnerable functions for tokenizing unpredictable user input, then we would strongly recommend upgrading to a version of NLTK without the vulnerability. For users unable to upgrade the execution time can be bounded by limiting the maximum length of an input to any of the vulnerable functions. Our recommendation is to implement such a limit.",
            "external_references": [
                {
                    "source_name": "cve",
                    "external_id": "CVE-2021-43854"
                }
            ]
        }
    ]
}